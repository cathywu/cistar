Introduction
----------------------

Why Flow?
********
Traffic systems can often be modeled by complex (nonlinear and coupled) dynamical systems for which classical analysis tools struggle to provide the understanding sought by transportation agencies, planners, and control engineers, mostly because of difficulty to provide analytical results on these. Deep reinforcement learning (RL) provides an opportunity to study complex traffic control problems involving interactions of humans, automated vehicles, and sensing infrastructure. The resulting control laws and emergent behaviors of the vehicles provide insight and understanding of the potential for automation of traffic through mixed fleets of autonomous and manned vehicles.

Flow is a computational framework integrating open-source deep learning and simulation tools, to support the development of controllers for automated vehicles in the presence of complex nonlinear dynamics in traffic. Leveraging recent advances in deep RL, Flow enables the use of RL methods such as policy gradient for traffic control and allows for benchmarking of the performance of classical (including hand-designed) controllers with learned control laws. Model-free learning RL methods naturally select policies that yield traffic flow improvements previously discovered by model-driven approaches, such as stabilization, platooning, and efficient vehicle spacing, known to improve ring road and intersection efficiency. Remarkably, by effectively leveraging the structure of the human driving behavior, the learned policies surpass the performance of state-of-the-art controllers designed for automated vehicles.
